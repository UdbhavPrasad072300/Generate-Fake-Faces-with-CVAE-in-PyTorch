{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Faces with CVAE in PyTorch [TRAIN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torchvision import datasets, transforms, models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import math\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformObj = transforms.Compose([\n",
    "    transforms.Resize(64),\n",
    "    transforms.CenterCrop(64),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot = \"./celeba/\"\n",
    "\n",
    "dataset = datasets.ImageFolder(root=dataroot, transform=transformObj)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, latent_size=100):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        self.latent_size = latent_size\n",
    "        \n",
    "        self.l1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=4, stride=2, padding=1)\n",
    "        self.l1b = nn.BatchNorm2d(32)\n",
    "        self.l2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=2, padding=1)\n",
    "        self.l2b = nn.BatchNorm2d(64)\n",
    "        self.l3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=4, stride=2, padding=1)\n",
    "        self.l3b = nn.BatchNorm2d(128)\n",
    "        self.l4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=4, stride=2, padding=1)\n",
    "        self.l4b = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.l41 = nn.Linear(256*4*4, self.latent_size)\n",
    "        self.l42 = nn.Linear(256*4*4, self.latent_size)\n",
    "        \n",
    "        self.f = nn.Linear(self.latent_size, 256*4*4)\n",
    "        \n",
    "        self.l5 = nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=4, stride=2, padding=1)\n",
    "        self.l6 = nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=4, stride=2, padding=1)\n",
    "        self.l7 = nn.ConvTranspose2d(in_channels=64, out_channels=32, kernel_size=4, stride=2, padding=1)\n",
    "        self.l8 = nn.ConvTranspose2d(in_channels=32, out_channels=3, kernel_size=4, stride=2, padding=1)\n",
    "        \n",
    "    def encoder(self, x_in):\n",
    "        h = F.leaky_relu(self.l1b(self.l1(x_in)))\n",
    "        h = F.leaky_relu(self.l2b(self.l2(h)))\n",
    "        h = F.leaky_relu(self.l3b(self.l3(h)))\n",
    "        h = F.leaky_relu(self.l4b(self.l4(h)))\n",
    "        \n",
    "        h = h.view(h.size(0), -1)\n",
    "        \n",
    "        return self.l41(h), self.l42(h)\n",
    "    \n",
    "    def decoder(self, z):\n",
    "        z = self.f(z)\n",
    "        z = z.view(-1, 256, 4, 4)\n",
    "        \n",
    "        z = F.leaky_relu(self.l5(z))\n",
    "        z = F.leaky_relu(self.l6(z))\n",
    "        z = F.leaky_relu(self.l7(z))\n",
    "        z = torch.sigmoid(self.l8(z))\n",
    "        \n",
    "        return z\n",
    "    \n",
    "    def sampling(self, mu, log_var):\n",
    "        std = torch.exp(0.5*log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return torch.add(eps.mul(std), mu)\n",
    "    \n",
    "    def forward(self, x_in):\n",
    "        mu, log_var = self.encoder(x_in)\n",
    "        z = self.sampling(mu, log_var)\n",
    "        return self.decoder(z), mu, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (l1): Conv2d(3, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (l1b): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (l2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (l2b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (l3): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (l3b): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (l4): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (l4b): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (l41): Linear(in_features=4096, out_features=100, bias=True)\n",
       "  (l42): Linear(in_features=4096, out_features=100, bias=True)\n",
       "  (f): Linear(in_features=100, out_features=4096, bias=True)\n",
       "  (l5): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (l6): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (l7): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (l8): ConvTranspose2d(32, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae = VAE()\n",
    "    \n",
    "vae.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 32, 32]           1,568\n",
      "       BatchNorm2d-2           [-1, 32, 32, 32]              64\n",
      "            Conv2d-3           [-1, 64, 16, 16]          32,832\n",
      "       BatchNorm2d-4           [-1, 64, 16, 16]             128\n",
      "            Conv2d-5            [-1, 128, 8, 8]         131,200\n",
      "       BatchNorm2d-6            [-1, 128, 8, 8]             256\n",
      "            Conv2d-7            [-1, 256, 4, 4]         524,544\n",
      "       BatchNorm2d-8            [-1, 256, 4, 4]             512\n",
      "            Linear-9                  [-1, 100]         409,700\n",
      "           Linear-10                  [-1, 100]         409,700\n",
      "           Linear-11                 [-1, 4096]         413,696\n",
      "  ConvTranspose2d-12            [-1, 128, 8, 8]         524,416\n",
      "  ConvTranspose2d-13           [-1, 64, 16, 16]         131,136\n",
      "  ConvTranspose2d-14           [-1, 32, 32, 32]          32,800\n",
      "  ConvTranspose2d-15            [-1, 3, 64, 64]           1,539\n",
      "================================================================\n",
      "Total params: 2,614,091\n",
      "Trainable params: 2,614,091\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 1.50\n",
      "Params size (MB): 9.97\n",
      "Estimated Total Size (MB): 11.52\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(vae, (3, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG_model, self).__init__()\n",
    "        self.model_layers = models.vgg.vgg19(pretrained=True).features\n",
    "        self.content_layers = [\"31\", \"33\", \"35\"]\n",
    "        \n",
    "        for parameter in self.model_layers.parameters():\n",
    "            parameter.requires_grad = False\n",
    "        \n",
    "    def forward(self, image):\n",
    "        batch_size = image.size(0)\n",
    "        output = image\n",
    "        output_layers = []\n",
    "        for name, module in self.model_layers.named_children():\n",
    "            output = module(output)\n",
    "            if name in self.content_layers:\n",
    "                output_layers.append(output.view(batch_size, -1))\n",
    "        return output_layers\n",
    "    \n",
    "    def feature_perceptual_loss(self, recon_x, x):\n",
    "        total_loss = 0\n",
    "        for x1, x2 in zip(recon_x, x):\n",
    "            total_loss += F.mse_loss(x1, x2)\n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(vae.parameters(), lr=0.0005)\n",
    "\n",
    "def loss_function(recon_x, x, mu, log_var, vgg_model):\n",
    "    \n",
    "    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    #MSL = F.mse_loss(recon_x, x)\n",
    "    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp()) # KL Divergence from MIT 6.S191\n",
    "    #return (MSL + KLD)\n",
    "    \n",
    "    x_f = vgg_model(x)\n",
    "    recon_x_f = vgg_model(recon_x)\n",
    "    FPL = vgg_model.feature_perceptual_loss(recon_x_f, x_f)\n",
    "    \n",
    "    return (BCE + KLD + FPL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    vae.train()\n",
    "    \n",
    "    vgg = VGG_model().to(device)\n",
    "\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(dataloader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        r_batch, mu, log_var = vae(data)\n",
    "\n",
    "        loss = loss_function(r_batch, data, mu, log_var, vgg)\n",
    "\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        if batch_idx%2500==0:\n",
    "            print(\"Batch no. finished in Epoch: \", batch_idx)\n",
    "    print(\"-------------------------------------------------\")\n",
    "    print('Epoch: {} Train mean loss: {:.8f}'.format(epoch, train_loss / len(dataloader.dataset)))\n",
    "    print(\"-------------------------------------------------\")\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch no. finished in Epoch:  0\n",
      "Batch no. finished in Epoch:  2500\n",
      "Batch no. finished in Epoch:  5000\n",
      "Batch no. finished in Epoch:  7500\n",
      "Batch no. finished in Epoch:  10000\n",
      "Batch no. finished in Epoch:  12500\n",
      "-------------------------------------------------\n",
      "Epoch: 1 Train mean loss: 6444.45138089\n",
      "-------------------------------------------------\n",
      "Batch no. finished in Epoch:  0\n",
      "Batch no. finished in Epoch:  2500\n",
      "Batch no. finished in Epoch:  5000\n",
      "Batch no. finished in Epoch:  7500\n",
      "Batch no. finished in Epoch:  10000\n",
      "Batch no. finished in Epoch:  12500\n",
      "-------------------------------------------------\n",
      "Epoch: 2 Train mean loss: 6341.52569205\n",
      "-------------------------------------------------\n",
      "Batch no. finished in Epoch:  0\n",
      "Batch no. finished in Epoch:  2500\n",
      "Batch no. finished in Epoch:  5000\n",
      "Batch no. finished in Epoch:  7500\n",
      "Batch no. finished in Epoch:  10000\n",
      "Batch no. finished in Epoch:  12500\n",
      "-------------------------------------------------\n",
      "Epoch: 3 Train mean loss: 6322.78354269\n",
      "-------------------------------------------------\n",
      "Batch no. finished in Epoch:  0\n",
      "Batch no. finished in Epoch:  2500\n",
      "Batch no. finished in Epoch:  5000\n",
      "Batch no. finished in Epoch:  7500\n",
      "Batch no. finished in Epoch:  10000\n",
      "Batch no. finished in Epoch:  12500\n",
      "-------------------------------------------------\n",
      "Epoch: 4 Train mean loss: 6313.98595671\n",
      "-------------------------------------------------\n",
      "Batch no. finished in Epoch:  0\n",
      "Batch no. finished in Epoch:  2500\n",
      "Batch no. finished in Epoch:  5000\n",
      "Batch no. finished in Epoch:  7500\n",
      "Batch no. finished in Epoch:  10000\n",
      "Batch no. finished in Epoch:  12500\n",
      "-------------------------------------------------\n",
      "Epoch: 5 Train mean loss: 6308.65873600\n",
      "-------------------------------------------------\n",
      "Batch no. finished in Epoch:  0\n",
      "Batch no. finished in Epoch:  2500\n",
      "Batch no. finished in Epoch:  5000\n",
      "Batch no. finished in Epoch:  7500\n",
      "Batch no. finished in Epoch:  10000\n",
      "Batch no. finished in Epoch:  12500\n",
      "-------------------------------------------------\n",
      "Epoch: 6 Train mean loss: 6304.80212494\n",
      "-------------------------------------------------\n",
      "Batch no. finished in Epoch:  0\n",
      "Batch no. finished in Epoch:  2500\n",
      "Batch no. finished in Epoch:  5000\n",
      "Batch no. finished in Epoch:  7500\n",
      "Batch no. finished in Epoch:  10000\n",
      "Batch no. finished in Epoch:  12500\n",
      "-------------------------------------------------\n",
      "Epoch: 7 Train mean loss: 6301.83484201\n",
      "-------------------------------------------------\n",
      "Batch no. finished in Epoch:  0\n",
      "Batch no. finished in Epoch:  2500\n",
      "Batch no. finished in Epoch:  5000\n",
      "Batch no. finished in Epoch:  7500\n",
      "Batch no. finished in Epoch:  10000\n",
      "Batch no. finished in Epoch:  12500\n",
      "-------------------------------------------------\n",
      "Epoch: 8 Train mean loss: 6299.52149335\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "n_epoches = 8\n",
    "\n",
    "loss_hist = []\n",
    "\n",
    "for epoch in range(1, n_epoches+1):\n",
    "    loss_epoch = train(epoch)\n",
    "    loss_hist.append(loss_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    counter = 0\n",
    "    for i in range(100): \n",
    "        counter += 1\n",
    "        z = (torch.rand(100)*2).to(device)\n",
    "        sample = vae.decoder(z).to(device)\n",
    "        save_image(sample.view(3, 64, 64), './samplesFACES/sample' + str(counter) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(vae.state_dict(), \"./model_weight/wf.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAERCAYAAABsNEDqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAnS0lEQVR4nO3de3RV9Z338fc39wuBQC4H5CKK4XJQQBsvVURQQ9U6pdbVUcdxOh0d2z61rZ1pp86secZ2+nSeto9OO522OtRS7bRjpxfbOtVaqBfQIirUG9eAgkjAXIBAQiDX7/PH2YFDTEICOdnn5Hxea5119tm/vU++cbn45Pf77f3b5u6IiIgMVEbYBYiISGpRcIiIyKAoOEREZFAUHCIiMigKDhERGRQFh4iIDEraBIeZLTOzOjNbP4BjTzezJ83sNTN7xswmDUeNIiKpIG2CA3gQuGqAx94D/NDd5wD/DPzfRBUlIpJq0iY43H0VsC9+n5lNM7MnzGydmT1rZjODpijwZLD9NLBkGEsVEUlqaRMcfVgKfMrd3wN8DvhusP9V4Ppg+zqgyMxKQqhPRCTpZIVdQFjMbBRwMfAzM+venRu8fw74tpn9JbAKqAE6hrtGEZFklLbBQay31eju83o2uPtu4ENwNGCud/cDw1ueiEhyStuhKnc/CGw3sw8DWMzcYLvUzLr/2/w9sCykMkVEkk7aBIeZPQw8D8wws11mditwM3Crmb0KbODYJPhCYIuZVQMR4CshlCwikpRMy6qLiMhgpE2PQ0REhkZaTI6Xlpb61KlTwy5DRCSlrFu3rsHdy3ruT4vgmDp1KmvXrg27DBGRlGJmb/W2X0NVIiIyKAoOEREZFAWHiIgMioJDREQGRcEhIiKDouAQEZFBUXCIiMigKDj6sbK6nu88vS3sMkREkoqCox+rtzXwzd9Xc/BIe9iliIgkjYQFh5ktM7M6M1vfR/sSM3vNzF4xs7VmNj+u7Soz22Jm28zsrrj9XzSzmuCcV8zsmkTVD1AVjdDe6TyzpT6RP0ZEJKUkssfxIHBVP+1PAnODByn9FfAAgJllAt8Brib27O+bzCwad9433H1e8Ho8EYV3O3fKWEoKc1ixsTaRP0ZEJKUkLDjcfRWwr5/2Zj+2pnsh0L19AbDN3d909zbgJxx7TsawyswwrphVzjOb62jr6AqjBBGRpBPqHIeZXWdmm4HHiPU6ACYCb8cdtivY1+2OYIhrmZmNTXSNi6PjaWrtYM2bexP9o0REUkKoweHuv3T3mcAHgS8Hu623Q4P3+4BpwDxgD3BvX99tZrcHcydr6+tPfo5ifkUp+dmZGq4SEQkkxVVVwbDWNDMrJdbDmBzXPAnYHRxX6+6d7t4FfI/YsFZf37nU3SvdvbKs7F3LyQ9YXnYml1aUsmJjLXpaoohIiMFhZmeZmQXb5wE5wF7gJaDCzM4wsxzgRuDR4LgJcV9xHdDrFVtDbfHs8bxz8Aiv1xwYjh8nIpLUEvYgJzN7GFgIlJrZLuBuIBvA3e8Hrgf+wszagcPADcFkeYeZ3QH8DsgElrn7huBrv25m84gNXe0APpao+uNdPrOcDIMVG2uZM6l4OH6kiEjSsnQYfqmsrPRTfQLgn/7H8xw83M4Tdy4YoqpERJKbma1z98qe+5NijiMVLI5G2PxOEzv3toRdiohIqBQcA7Q4Oh6A5RvfCbkSEZFwKTgGaEpJATMiRbosV0TSnoJjEKqiEV7asY/9h9rCLkVEJDQKjkFYPDtCl8OTm+vCLkVEJDQKjkE4Z+IYxo/OY4XmOUQkjSk4BsHMuDJazqrqBo60d4ZdjohIKBQcg7Q4Op7D7Z38YVtD2KWIiIRCwTFIF51ZQlFuFss36OoqEUlPCo5BysnK4LIZZTy5uZbOrpF/172ISE8KjpNQFY3Q0NzGK2/vD7sUEZFhp+A4CYtmlpOdaRquEpG0pOA4CaPzsrnozBLdRS4iaUnBcZKqohHebDjEtrrmsEsRERlWCo6TdOWsCIB6HSKSdhQcJ+m04nzOmThGq+WKSNpRcJyCqmiEV95upK7pSNiliIgMGwXHKVg8O4I7PLlJix6KSPpQcJyCGZEiJo/LZ/kGDVeJSPpQcJwCM6Nq1nj+8MZeDrV2hF2OiMiwUHCcoqpohLaOLlZV14ddiojIsFBwnKLzp46luCBbl+WKSNpQcJyirMwMLp9ZzpOb62jv7Aq7HBGRhFNwDIHF0QgHDrfz0o59YZciIpJwCo4hsGB6GblZGRquEpG0kLDgMLNlZlZnZuv7aF9iZq+Z2StmttbM5se1XWVmW8xsm5ndFbd/nJmtMLOtwfvYRNU/GAU5Wcw/q5TlG2px1zM6RGRkS2SP40Hgqn7anwTmuvs84K+ABwDMLBP4DnA1EAVuMrNocM5dwJPuXhGcf1fPLw1LVTRCTeNhNu1pCrsUEZGESlhwuPsqoM9Bf3dv9mN/nhcC3dsXANvc/U13bwN+AiwJ2pYADwXbDwEfHOq6T9YVsyKYadFDERn5Qp3jMLPrzGwz8BixXgfARODtuMN2BfsAIu6+ByB4L+/nu28PhsDW1tcn/h6LsqJczpsylhWbdBe5iIxsoQaHu//S3WcS6zl8OdhtvR16Et+91N0r3b2yrKzsFKocuKpohPU1B6lpPDwsP09EJAxJcVVVMKw1zcxKifUwJsc1TwJ2B9u1ZjYBIHhPqtUFq6KxZ3T8XsNVIjKChRYcZnaWmVmwfR6QA+wFXgIqzOwMM8sBbgQeDU57FPhIsP0R4NfDW3X/ppWNYlpZoeY5RGREy0rUF5vZw8BCoNTMdgF3A9kA7n4/cD3wF2bWDhwGbggmyzvM7A7gd0AmsMzdNwRf+1Xgp2Z2K7AT+HCi6j9ZVdHxPPDsmxw43M6Y/OywyxERGXKWDvcdVFZW+tq1a4flZ617az/X37eaf7txHkvmTTzxCSIiScrM1rl7Zc/9STHHMZKcO7mY0lG5LNdwlYiMUAqOIZaRYVRFy1m5pZ7Wjs6wyxERGXIKjgSoikZobu3g+Tf2hl2KiMiQU3AkwMXTSinIydTVVSIyIik4EiAvO5PLppfx+021dHWN/IsPRCS9KDgSpCoaofZgK6/VHAi7FBGRIaXgSJDLZ5aTmWGs2Ki1q0RkZFFwJEhxQQ4XTB2neQ4RGXEUHAlUFY1QXdvMjoZDYZciIjJkFBwJ1L3ooXodIjKSKDgSaPK4AmaOL1JwiMiIouBIsMWzx7P2rX3sbW4NuxQRkSGh4EiwxdEIXQ5Pbk6qR4eIiJw0BUeCzT5tNKeNydNwlYiMGAqOBDMzqqIRnt1az+E2LXooIqlPwTEMqqLjOdLexXPbGsIuRUTklCk4hsGFZ46jKC+L5Rt0F7mIpD4FxzDIzsxg0YxyntpcR6cWPRSRFKfgGCaLZ0fYe6iNP+7cH3YpIiKnRMExTC6bXkZ2pmm4SkRSnoJjmBTlZfPeaaWs2FiLu4arRCR1KTiG0eJohB17W9hW1xx2KSIiJ03BMYy6Fz1crpsBRSSFKTiGUWR0HnMnjVFwiEhKU3AMs8Wzx/Pq243UHjwSdikiIiclYcFhZsvMrM7M1vfRfrOZvRa8VpvZ3Li2z5jZejPbYGZ3xu3/opnVmNkrweuaRNWfKN3DVb/fpF6HiKSmRPY4HgSu6qd9O3CZu88BvgwsBTCzs4G/Bi4A5gLXmllF3HnfcPd5wevxhFSeQBXlozi9pIDlGxQcIpKaEhYc7r4K2NdP+2p3774bbg0wKdieBaxx9xZ37wBWAtclqs7hZmZUzYrw/Bt7aW7tCLscEZFBS5Y5jluB3wbb64EFZlZiZgXANcDkuGPvCIa3lpnZ2L6+0MxuN7O1Zra2vr4+cZWfhMWzx9PW2cXKLclVl4jIQIQeHGa2iFhwfAHA3TcBXwNWAE8ArwLdf5rfB0wD5gF7gHv7+l53X+rule5eWVZWlrD6T8Z7Th/LuMIcVmzUXeQiknpCDQ4zmwM8ACxx973d+939++5+nrsvIDbctTXYX+vune7eBXyP2DxIysnMMC6fGVv0sL2zK+xyREQGJbTgMLMpwCPALe5e3aOtPO6YDwEPB58nxB12HbFhrZS0OBrh4JEOXtze5zSQiEhSykrUF5vZw8BCoNTMdgF3A9kA7n4/8E9ACfBdMwPocPfK4PRfmFkJ0A58Mm4S/etmNg9wYAfwsUTVn2iXVpSRl53Bio21XHJWadjliIgMWMKCw91vOkH7bcBtfbRd2sf+W4agtKSQn5PJ/LPKWL7hHe7+kyhBeIqIJL3QJ8fT2eJohN0HjrBh98GwSxERGTAFR4iumFVOhsEKrV0lIilEwRGiklG5vOf0sQoOEUkpCo6QVUUjbNxzkLf3tYRdiojIgCg4QlYVHQ9o0UMRSR0KjpCdUVpIRfkoDVeJSMpQcCSBqmiEF7bvo7GlLexSREROSMGRBKqiETq7nKe31IVdiojICSk4ksDcScWUF+VquEpEUoKCIwlkZBhXRiOs3FLPkfbOsMsREemXgiNJVEUjHGrr5Pk39p74YBGRECk4ksTF00oozMlkuYarRCTJKTiSRG5WJgtnlPP7TbV0dXnY5YiI9GlAwWFmhWaWEWxPN7MPmFl2YktLP1XRCPVNrbyyqzHsUkRE+jTQHscqIM/MJgJPAh8FHkxUUelq0YxysjJMV1eJSFIbaHCYu7cQexrfv7v7dUA0cWWlpzEF2Vx45jgFh4gktQEHh5m9F7gZeCzYl7CHQKWzqlkRttU182Z9c9iliIj0aqDBcSfw98Av3X2DmZ0JPJ2wqtLYldEIoGd0iEjyGlBwuPtKd/+Au38tmCRvcPdPJ7i2tDRpbAGzTxut4BCRpDXQq6r+y8xGm1khsBHYYmafT2xp6asqGmHdzv00NLeGXYqIyLsMdKgq6u4HgQ8CjwNTgFsSVVS6q4pGcIcn9YwOEUlCAw2O7OC+jQ8Cv3b3dkB3qSVIdMJoJhbna7hKRJLSQIPjP4AdQCGwysxOBw4mqqh0Z2ZURSM8u7WBlraOsMsRETnOQCfHv+XuE939Go95C1iU4NrS2uJohNaOLp7d2hB2KSIixxno5PgYM/tXM1sbvO4l1vvo75xlZlZnZuv7aL/ZzF4LXqvNbG5c22fMbL2ZbTCzO+P2jzOzFWa2NXgfO7BfM/Wcf8Y4RudlsXyDhqtEJLkMdKhqGdAE/GnwOgj84ATnPAhc1U/7duAyd58DfBlYCmBmZwN/DVwAzAWuNbOK4Jy7gCfdvYLY0id3DbD+lJOdmcEVsyI8tbmWjs6usMsRETlqoMExzd3vdvc3g9eXgDP7O8HdVwH7+mlf7e77g49rgEnB9ixgjbu3uHsHsBK4LmhbAjwUbD9EbLJ+xKqKRtjf0s66t/af+GARkWEy0OA4bGbzuz+Y2SXA4SGs41bgt8H2emCBmZWYWQFwDTA5aIu4+x6A4L18CGtIOguml5GTmaFndIhIUhnoelMfB35oZmOCz/uBjwxFAWa2iFhwzAdw901m9jVgBdAMvAoM+tIiM7sduB1gypQpQ1HqsBuVm8UlZ5WwYmMt//j+WZhZ2CWJiAz4qqpX3X0uMAeY4+7nApef6g83sznAA8ASdz/6zFR3/767n+fuC4gNd20NmmrNbEJw7gSgrp+al7p7pbtXlpWVnWqpoamKjmfnvhaqa7XooYgkh0E9AdDdDwZ3kAP8zan8YDObAjwC3OLu1T3ayuOO+RDwcND0KMd6Oh8Bfn0qNaSCK2fFRuNWbHwn5EpERGJOZWn0fsdNzOxhYCFQama7gLuBbAB3vx/4J6AE+G4wBNPh7pXB6b8wsxKgHfhk3CT6V4GfmtmtwE7gw6dQf0ooH53HuVOKWb6xljsurzjxCSIiCXYqwdHvkiPuftMJ2m8Dbuuj7dI+9u8FrhhogSNFVTTC15/YwjsHjjB+TF7Y5YhImut3qMrMmszsYC+vJuC0Yaox7S3ufkaHFj0UkSTQb3C4e5G7j+7lVeTuegLgMJlWNoozSgtZvkHzHCISvkFNjks4zIzF0Qhr3tzLwSPtYZcjImlOwZEiqqIR2judlVvqwy5FRNKcgiNFnDtlLCWFOXpGh4iETsGRIjIzjCtnRXh6cx1tHVr0UETCo+BIIVXRCE2tHbywfe+JDxYRSRAFRwqZX1FKfnamhqtEJFQKjhSSl53JpRWlrNhYi7se+S4i4VBwpJjFs8ez58AR1tfoke8iEg4FR4q5fGY5GaZFD0UkPAqOFDOuMIfKqeP0cCcRCY2CIwUtjkbY/E4Tb+9rCbsUEUlDCo4UtDg6HkC9DhEJhYIjBU0pKWBGpEjzHCISCgVHiqqKRnhx+z72H2oLuxQRSTMKjhS1eHaELoenNvf52HURkYRQcKSocyaOYfzoPN1FLiLDTsGRosyMK6PlrNpaz5H2zrDLEZE0ouBIYYuj42lp6+QP2xrCLkVE0oiCI4VddGYJRblZGq4SkWGl4EhhOVkZXDajjN9vqqWzS4seisjwUHCkuMWzx9PQ3MYrb+8PuxQRSRMKjhS3cEYZ2Zmmu8hFZNgoOFLc6LxsLjqzRPMcIjJsEhYcZrbMzOrMbH0f7Teb2WvBa7WZzY1r+6yZbTCz9Wb2sJnlBfu/aGY1ZvZK8LomUfWnkqpohDfrD7GtrjnsUkQkDSSyx/EgcFU/7duBy9x9DvBlYCmAmU0EPg1UuvvZQCZwY9x533D3ecHr8YRUnmKunBUBUK9DRIZFwoLD3VcB+/ppX+3u3TO6a4BJcc1ZQL6ZZQEFwO5E1TkSnFaczzkTx2jRQxEZFskyx3Er8FsAd68B7gF2AnuAA+6+PO7YO4LhrWVmNravLzSz281srZmtra+vT2TtSaEqGuHltxupazoSdikiMsKFHhxmtohYcHwh+DwWWAKcAZwGFJrZnweH3wdMA+YRC5V7+/ped1/q7pXuXllWVpa4XyBJvG/2eNzhjh+/zOZ39DxyEUmcUIPDzOYADwBL3H1vsPtKYLu717t7O/AIcDGAu9e6e6e7dwHfAy4Io+5kNGN8EV+7/hyq65p4/7ee44uPbuBAS3vYZYnICBRacJjZFGKhcIu7V8c17QQuMrMCMzPgCmBTcM6EuOOuA3q9Yitd3XD+FJ7+24XcdMFkfvj8Dhbd+wwPv7hTd5WLyJAy98T8o2JmDwMLgVKgFrgbyAZw9/vN7AHgeuCt4JQOd68Mzv0ScAPQAbwM3OburWb2n8SGqRzYAXzM3fecqJbKykpfu3btkP1uqWDD7gN86dGNvLhjH+dMHMMXPzCb95ze55SQiMi7mNm67n+Xj9ufqOBIJukYHADuzqOv7uZfHt9E7cFWPnTeRO66aiblo/PCLk1EUkBfwRH65LgkjpmxZN5EnvrbhfyvhdP4zat7uPzelSxd9QZtHV1hlyciKUrBkQYKc7P4u6tmsvyzC7jwjHH8y+ObuerfVrGyeuRfpiwiQ0/BkUamlhby/b88nx/85fm4w0eWvchtD61l596WsEsTkRSi4EhDi2aW88Sdl/KFq2ay+o0GrvzGSu753RZa2jrCLk1EUoCCI03lZmXyiYXTePpzC7nm7PF8++ltXHHvSv7n1d2kwwUTInLyFBxpLjI6j2/eeC4/+/h7GVuQw6cefpkbl65h0x7dfS4ivVNwCADnTx3H/3xqPl+57my21Dbx/m89y92/Xk9jS1vYpYlIklFwyFGZGcbNF57OM59byJ9fdDr/ueYtFt3zDP/1gu4+F5FjFBzyLsUFOfzzkrP5zacupSJSxD/88nWWfOc51r3V5yr5IpJGFBzSp+hpo/nv2y/iWzedS0NTG9ff9zyf/e9XqD2opdtF0pmCQ/plZnxg7mk89bnL+OSiaTz22h4uv+cZ7l+pu89F0pWCQwakICeLz79vJiv+ZgHvnVbCV3+7mau+uYqnt9SFXZqIDDMFhwzK6SWFPPCR8/nBR88H4KM/eIlbH3yJHQ2HQq5MRIaLgkNOyqIZ5Txx5wLuunoma97cy+JvrOL//W4zh1p197nISKfgkJOWk5XBxy+bxlOfW8i1cybwnaff4Ip7V/LrV2p097nICKbgkFMWGZ3Hv94wj59//L2UjMrhMz95hRuWrmHjbt19LjISKThkyFROHcejd8znX647h621TVz778/yv3+lu89FRhoFhwypzAzjzy6cwjOfW8QtF53Oj194i4X3PMOP1rylu89FRggFhyTEmIJsvrTkbB779KXMiBTxj79az5/8+3O8tEN3n4ukOgWHJNSsCaP5ye0X8e0/O5f9LW18+P7nufMnL/POAd19LpKqssIuQEY+M+PaOadx+cxyvvv0Gyxd9SbLN9by0UumcuWsCHMmFZOZYWGXKSIDZOlw2WRlZaWvXbs27DIk8NbeQ3zlsU2s2FSLO4zJz2b+WaUsmF7KgullTBiTH3aJIgKY2Tp3r+y5Xz0OGXanlxSy9C8q2Xeojee2NbCqup5nt9bz2Ot7AKgoH8WlFWUsmF7KhWeUkJ+TGXLFIhJPPQ5JCu5OdW0zq6rrWbW1nhe376O1o4ucrAwumDqOBdNLubSijJnjizDTsJbIcOirx6HgkKR0pL2TF7fvOxok1bXNAJQV5XJpRSmXTS9j/lmllIzKDblSkZFr2IeqzGwZcC1Q5+5n99J+M/CF4GMz8Al3fzVo+yxwG+DA68BH3f2ImY0D/huYCuwA/tTd9yfqd5Dw5GVnsmB6GQumlwHwzoEjrNpaz6rqep7aXMcjf6wB4OyJo1lQETvuvCljycnShYIiiZawHoeZLSAWCD/sIzguBja5+34zuxr4ortfaGYTgeeAqLsfNrOfAo+7+4Nm9nVgn7t/1czuAsa6+xd6fndP6nGMLJ1dzvqaA8HcSAN/3Lmfji6nMCeT904rYcH0Mi6tKGNqSYGGtUROwbD3ONx9lZlN7ad9ddzHNcCkHnXlm1k7UADsDvYvARYG2w8Bz3Cs1yJpIjPDmDu5mLmTi/nUFRU0HWln9Rt7eXZrPauqG/j9ptgzQiaPy2dBRSxELj6rhNF52SFXLjIyJMtVVbcCvwVw9xozuwfYCRwGlrv78uC4iLvvCY7bY2blfX2hmd0O3A4wZcqURNYuISvKy+Z9s8fzvtnjAdjRcIhnt9azsrqBX71cw49f2ElmhnHu5OKjw1/nTByje0dETlJCJ8eDHsdvehuqijtmEfBdYL677zWzscAvgBuARuBnwM/d/Udm1ujuxXHn7nf3sSeqQ0NV6auto4uXd+5n1dbYsNbrNQdwh+KCbC45q5TLKsq4dHqp7h0R6UVS3sdhZnOAB4Cr3X1vsPtKYLu71wfHPAJcDPwIqDWzCUFvYwKg55ZKv3KyMrjwzBIuPLOEz78P9ja38ty2Bp7dGrt/5LHXdO+IyGCFFhxmNgV4BLjF3avjmnYCF5lZAbGhqiuA7u7Co8BHgK8G778evoplJCgZlcuSeRNZMm8i7s6W2iaerW5g1dZ6fvTCWyz7w/ZY2JwxjksrYneyz4jo3hGReIm8quphYhPZpUAtcDeQDeDu95vZA8D1wFvBKR3dXSIz+xKxoaoO4GXgNndvNbMS4KfAFGIB82F3P+FyqxqqkoE43NbJizuCe0eq69laF7t3pLwol/kVpZwzcQzTI0VUREZRNipXYSIjnm4AVHDIIO05cJhnqxtYubWe1dsa2N/SfrStuCCbivJRVESKmF4+KgiUIkpH5ShQZMRQcCg45BS4O/VNrVTXNlNd28TWuia2BtsHj3QcPa64IJvp5bFeSXfvpKJcgSKpKSknx0VShZlRPjqP8tF5zK8oPbrf3alrao2FSW0zW+uaqK5t5tFXd9MUFyhjC7JjvZMgUM4KeimlWjJFUpCCQ+QUmBmR0XlERudxaUXZ0f3xgVJd28zW2iaqa5v49cu7aWo9FijjCnOCIa+gh1IeCxetwSXJTMEhkgD9BUrtwe5AaWJbXXOvgVJSmHO0VzI9EsylRIoYV5gTxq8jchwFh8gwMjPGj8lj/Ji8ows4QixQ3jl45Oi8ydbaZqrrmvjVyzXvCpRj8ydFVAThokCR4aTgEEkCZsaEMflMGJPfa6B0D3d1B8ojf6yhOS5QSkflHB3mOitSxLTSQiaOjX2fVgyWoabgEEli8YFyWY9A2XPgyHHDXdW1zfyiR6CYxe5DmVicz8SxBcF7PpOC94nF+RTm6p8BGRz9HyOSgsyM04rzOa04n4Uzjq316e7sPnCEtxoOsavxMDX7D1MTvL/6diNPrN9De+fxl+AXF2THAiUuTCaNzWdicQETx+YztiBblxLLcRQcIiOImR0Ngd50dsXuR6lpbGFXXKjUNB5me8MhntvWQEtb53Hn5GdnHg2U44Ml9rm8KE8rDacZBYdIGsnMODY5/57T393u7jS2tFPTeLhHsLRQ03iY13Y1HncHPUBWhjGhOC8IrIJ3DYVNKM4jN0uLRo4kCg4ROcrMGFuYw9jCHM6eOKbXY1raOqjZf/hdQ2E1jYf5w7YGapuO0HNBivKiXE7rZX6l+71ID9lKKQoOERmUgpys2KXAkaJe29s6uqg9eKTXHsuGmgOs2FBLW2dXj+/MpKwol9JRuZSNyqWs6NirdFT8do56L0lAwSEiQyonK4PJ4wqYPK6g1/auLqehufW4Hkt9UysNza3UN7XyRn0za7bvpbHHkFi3MfnZlI7KCcIk77igObY/l5LCXM29JIiCQ0SGVUbGsXW/zpvS9wM8Wzs62dvcdjRQjr6aj4XM67saqW9q5VCPCX2ADINxhceHSVlRXI8mLnDG5OvKscFQcIhIUsrNyjx6yfGJHGrtoCEuUOJDpr6pjfrmVt6sP0R9U+u7hskAsjONslG5lBb1M1QWvOu+FwWHiIwAhblZFOZmcXpJYb/HuTsHD3dQ33zkaKDEB01Dcyt7DhzhtZoD7G1upauXp07kZmUwtiCH4oJsiguy47ZzGFuQTXH+8Z/HBPtG0h38Cg4RSRtmxpjgH/Ozyvs/trPL2Xeo7bj5l7qmVva3tLH/UBuNh9tpbGlja10zjS2x7Y7ekiYwKjeLMfnZjC08Fi7xoVPc3da9XZDD6PzspJynUXCIiPQiM8OODlcNhLtzqK0zFiot7TQebmN/SzsHWmLv+1vaOBC8Nx6O3SvTGGz39Tw9Mxidl92jRxOES1+9ncJsinKzEjpno+AQERkCZsao3CxG5WYxedzAz+vqcg4eaacxLlQaW9qCz/Hbbew71MYb9c00Hmo/btXknjIzLAiYbL5y3TlcdGbJEPyGxyg4RERClJFhQQ8ih6n0P0cTr72ziwOH248Okx0NnuN6O+2MyR/6mysVHCIiKSg7M4PSUbmhPH545Ezzi4jIsFBwiIjIoCg4RERkUBIWHGa2zMzqzGx9H+03m9lrwWu1mc0N9s8ws1fiXgfN7M6g7YtmVhPXdk2i6hcRkd4lcnL8QeDbwA/7aN8OXObu+83samApcKG7bwHmAZhZJlAD/DLuvG+4+z2JKlpERPqXsOBw91VmNrWf9tVxH9cAk3o57ArgDXd/a4jLExGRk5Qscxy3Ar/tZf+NwMM99t0RDG8tM7O+l9YUEZGECD04zGwRseD4Qo/9OcAHgJ/F7b4PmEZsKGsPcG8/33u7ma01s7X19fVDXbaISNoK9QZAM5sDPABc7e57ezRfDfzR3Wu7d8Rvm9n3gN/09d3uvpTYvAlmVm9mJzvcVQo0nOS5YUilelOpVkitelOpVkitelOpVji1ent5Mn2IwWFmU4BHgFvcvbqXQ26ixzCVmU1w9z3Bx+uAXq/Y6sndy06hzrXuXnmy5w+3VKo3lWqF1Ko3lWqF1Ko3lWqFxNSbsOAws4eBhUCpme0C7gayAdz9fuCfgBLgu8Eqjh3dv5yZFQBVwMd6fO3XzWwe4MCOXtpFRCTBEnlV1U0naL8NuK2PthZiodJz/y1DU52IiJys0CfHU8DSsAsYpFSqN5VqhdSqN5VqhdSqN5VqhQTUa97XE0RERER6oR6HiIgMioJDREQGRcHRDzO7ysy2mNk2M7sr7Hr6c6JFJZOJmU02s6fNbJOZbTCzz4RdU1/MLM/MXjSzV4NavxR2TSdiZplm9rKZ9XmfU7Iwsx1m9nqwaOnasOs5ETMrNrOfm9nm4P/f94ZdU2/6Wyx2SL5fcxy9CxZYrCZ2WfAu4CXgJnffGGphfTCzBUAz8EN3PzvsevpjZhOACe7+RzMrAtYBH0zG/7YWu1a80N2bzSwbeA74jLuvCbm0PpnZ3wCVwGh3vzbsevpjZjuASndPiRvqzOwh4Fl3fyBY3aLA3RtDLqtfcYvFXjhU6/6px9G3C4Bt7v6mu7cBPwGWhFxTn9x9FbAv7DoGwt33uPsfg+0mYBMwMdyqeucxzcHH7OCVtH9tmdkk4P3EVmSQIWRmo4EFwPcB3L0t2UMjMOSLxSo4+jYReDvu8y6S9B+3VBasoHwu8ELIpfQpGPp5BagDVrh70tYKfBP4O6Ar5DoGyoHlZrbOzG4Pu5gTOBOoB34QDAU+YGaFYRc1AL0tFntKFBx9s172Je1fmqnIzEYBvwDudPeDYdfTF3fvdPd5xJb+v8DMknIo0MyuBercfV3YtQzCJe5+HrG16T4ZDLkmqyzgPOA+dz8XOAQk+9xnb4vFnjIFR992AZPjPk8CdodUy4gTzBf8Avixuz8Sdj0DEQxLPANcFW4lfboE+EAwb/AT4HIz+1G4JfXP3XcH73XEHth2QbgV9WsXsCuux/lzYkGSzN61WOxQUHD07SWgwszOCFL7RuDRkGsaEYIJ5+8Dm9z9X8Oupz9mVmZmxcF2PnAlsDnUovrg7n/v7pPcfSqx/1+fcvc/D7msPplZYXBxBMGQz2IGuHBpGNz9HeBtM5sR7LoCSLoLOnp412KxQyHUZdWTmbt3mNkdwO+ATGCZu28Iuaw+9baopLt/P9yq+nQJcAvwejB3APAP7v54eCX1aQLwUHBlSgbwU3dP+stcU0QE+GWwyGkW8F/u/kS4JZ3Qp4AfB39Mvgl8NOR6+tTPYrGn/t26HFdERAZDQ1UiIjIoCg4RERkUBYeIiAyKgkNERAZFwSEiIoOi4BAZAmbW2WM10iG7o9jMpqbCqseSPnQfh8jQOBwsSyIy4qnHIZJAwfMmvhY80+NFMzsr2H+6mT1pZq8F71OC/REz+2Xw/I9Xzezi4Ksyzex7wTNBlgd3sYuEQsEhMjTyewxV3RDXdtDdLwC+TWz1WoLtH7r7HODHwLeC/d8CVrr7XGLrIHWvVlABfMfdZwONwPUJ/W1E+qE7x0WGgJk1u/uoXvbvAC539zeDhR3fcfcSM2sg9jCr9mD/HncvNbN6YJK7t8Z9x1Riy7lXBJ+/AGS7+/8Zhl9N5F3U4xBJPO9ju69jetMat92J5iclRAoOkcS7Ie79+WB7NbEVbAFuJvZIWoAngU/A0QdIjR6uIkUGSn+1iAyN/LiVfgGecPfuS3JzzewFYn+o3RTs+zSwzMw+T+ypct2rrH4GWGpmtxLrWXwC2JPo4kUGQ3McIgkUzHFUuntD2LWIDBUNVYmIyKCoxyEiIoOiHoeIiAyKgkNERAZFwSEiIoOi4BARkUFRcIiIyKD8f0LK4w4CE2JyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_hist)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
