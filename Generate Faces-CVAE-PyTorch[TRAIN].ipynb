{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Faces with CVAE in PyTorch [TRAIN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import math\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformObj = transforms.Compose([\n",
    "    transforms.Resize(160),\n",
    "    transforms.CenterCrop(64),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot = \"./celeba/\"\n",
    "\n",
    "dataset = datasets.ImageFolder(root=dataroot, transform=transformObj)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, latent_size=100):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        self.latent_size = latent_size\n",
    "        \n",
    "        self.l1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=4, stride=2, padding=1)\n",
    "        self.l1b = nn.BatchNorm2d(32)\n",
    "        self.l2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=2, padding=1)\n",
    "        self.l2b = nn.BatchNorm2d(64)\n",
    "        self.l3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=4, stride=2, padding=1)\n",
    "        self.l3b = nn.BatchNorm2d(128)\n",
    "        self.l4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=4, stride=2, padding=1)\n",
    "        self.l4b = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.l41 = nn.Linear(256*4*4, self.latent_size)\n",
    "        self.l42 = nn.Linear(256*4*4, self.latent_size)\n",
    "        \n",
    "        self.f = nn.Linear(self.latent_size, 256*4*4)\n",
    "        \n",
    "        self.l5 = nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=4, stride=2, padding=1)\n",
    "        self.l6 = nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=4, stride=2, padding=1)\n",
    "        self.l7 = nn.ConvTranspose2d(in_channels=64, out_channels=32, kernel_size=4, stride=2, padding=1)\n",
    "        self.l8 = nn.ConvTranspose2d(in_channels=32, out_channels=3, kernel_size=4, stride=2, padding=1)\n",
    "        \n",
    "    def encoder(self, x_in):\n",
    "        h = F.leaky_relu(self.l1b(self.l1(x_in)))\n",
    "        h = F.leaky_relu(self.l2b(self.l2(h)))\n",
    "        h = F.leaky_relu(self.l3b(self.l3(h)))\n",
    "        h = F.leaky_relu(self.l4b(self.l4(h)))\n",
    "        \n",
    "        h = h.view(h.size(0), -1)\n",
    "        \n",
    "        return self.l41(h), self.l42(h)\n",
    "    \n",
    "    def decoder(self, z):\n",
    "        z = self.f(z)\n",
    "        z = z.view(-1, 256, 4, 4)\n",
    "        \n",
    "        z = F.leaky_relu(self.l5(z))\n",
    "        z = F.leaky_relu(self.l6(z))\n",
    "        z = F.leaky_relu(self.l7(z))\n",
    "        z = torch.sigmoid(self.l8(z))\n",
    "        \n",
    "        return z\n",
    "    \n",
    "    def sampling(self, mu, log_var):\n",
    "        std = torch.exp(0.5*log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return torch.add(eps.mul(std), mu)\n",
    "    \n",
    "    def forward(self, x_in):\n",
    "        mu, log_var = self.encoder(x_in)\n",
    "        z = self.sampling(mu, log_var)\n",
    "        return self.decoder(z), mu, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (l1): Conv2d(3, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (l1b): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (l2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (l2b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (l3): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (l3b): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (l4): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (l4b): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (l41): Linear(in_features=4096, out_features=100, bias=True)\n",
       "  (l42): Linear(in_features=4096, out_features=100, bias=True)\n",
       "  (f): Linear(in_features=100, out_features=4096, bias=True)\n",
       "  (l5): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (l6): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (l7): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (l8): ConvTranspose2d(32, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae = VAE()\n",
    "    \n",
    "vae.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 32, 32]           1,568\n",
      "       BatchNorm2d-2           [-1, 32, 32, 32]              64\n",
      "            Conv2d-3           [-1, 64, 16, 16]          32,832\n",
      "       BatchNorm2d-4           [-1, 64, 16, 16]             128\n",
      "            Conv2d-5            [-1, 128, 8, 8]         131,200\n",
      "       BatchNorm2d-6            [-1, 128, 8, 8]             256\n",
      "            Conv2d-7            [-1, 256, 4, 4]         524,544\n",
      "       BatchNorm2d-8            [-1, 256, 4, 4]             512\n",
      "            Linear-9                  [-1, 100]         409,700\n",
      "           Linear-10                  [-1, 100]         409,700\n",
      "           Linear-11                 [-1, 4096]         413,696\n",
      "  ConvTranspose2d-12            [-1, 128, 8, 8]         524,416\n",
      "  ConvTranspose2d-13           [-1, 64, 16, 16]         131,136\n",
      "  ConvTranspose2d-14           [-1, 32, 32, 32]          32,800\n",
      "  ConvTranspose2d-15            [-1, 3, 64, 64]           1,539\n",
      "================================================================\n",
      "Total params: 2,614,091\n",
      "Trainable params: 2,614,091\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 1.50\n",
      "Params size (MB): 9.97\n",
      "Estimated Total Size (MB): 11.52\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(vae, (3, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(vae.parameters(), lr=0.0005)\n",
    "\n",
    "def loss_function(recon_x, x, mu, log_var):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    #MSL = F.mse_loss(recon_x, x)\n",
    "    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp()) # KL Divergence from MIT 6.S191\n",
    "    #return (MSL + KLD)\n",
    "    return (BCE + KLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    vae.train()\n",
    "    \n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(dataloader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        r_batch, mu, log_var = vae(data)\n",
    "\n",
    "        loss = loss_function(r_batch, data, mu, log_var)\n",
    "\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        #if batch_idx%50==0:\n",
    "        #    print(\"Batch finished in Epoch: \", batch_idx)\n",
    "\n",
    "    print('Epoch: {} Train mean loss: {:.8f}'.format(epoch, train_loss / len(dataloader.dataset)))\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train mean loss: 7182.86641258\n",
      "Epoch: 2 Train mean loss: 7091.40843138\n",
      "Epoch: 3 Train mean loss: 7076.69890785\n",
      "Epoch: 4 Train mean loss: 7068.59607891\n",
      "Epoch: 5 Train mean loss: 7063.79310528\n",
      "Epoch: 6 Train mean loss: 7060.88451869\n",
      "Epoch: 7 Train mean loss: 7058.19276184\n",
      "Epoch: 8 Train mean loss: 7055.91989840\n",
      "Epoch: 9 Train mean loss: 7054.38496896\n",
      "Epoch: 10 Train mean loss: 7053.00824763\n",
      "Epoch: 11 Train mean loss: 7052.30444124\n",
      "Epoch: 12 Train mean loss: 7051.10189812\n",
      "Epoch: 13 Train mean loss: 7050.18044659\n",
      "Epoch: 14 Train mean loss: 7049.10372481\n",
      "Epoch: 15 Train mean loss: 7048.48082058\n"
     ]
    }
   ],
   "source": [
    "n_epoches = 15\n",
    "\n",
    "loss_hist = []\n",
    "\n",
    "for epoch in range(1, n_epoches+1):\n",
    "    loss_epoch = train(epoch)\n",
    "    loss_hist.append(loss_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    counter = 0\n",
    "    for i in range(100): \n",
    "        counter += 1\n",
    "        z = torch.rand(100).to(device)\n",
    "        sample = vae.decoder(z).to(device)\n",
    "        save_image(sample.view(3, 64, 64), './samplesFACES/sample' + str(counter) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(vae.state_dict(), \"./model_weight/wf.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAERCAYAAABsNEDqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAiDklEQVR4nO3de5RddX338fd35sz9zEwuM2cSchuSGUFIQtApoLRFsbSBpzWgVrQ0xRpEqnjpY/ug7VpWS2u901rFNmIEKtL6tLj0sYJiBFMMKAG5JCSQK5gwmUsSMrfM/fv8cfYkkzhnZs7MOWefy+e11lln79/e+8x3ZmXymd/+/fbe5u6IiIhMV1HYBYiISG5RcIiISFIUHCIikhQFh4iIJEXBISIiSVFwiIhIUgomOMxsk5m1m9n2aey7zMw2m9kzZvawmS3ORI0iIrmgYIIDuBNYO819Pw/c7e6rgb8F/iFdRYmI5JqCCQ533wIcHd9mZivM7AEze8LM/sfMzg02nQdsDpYfAtZlsFQRkaxWMMGRwEbgA+7+WuAvgNuD9qeBtwbL1wDVZjY/hPpERLJOJOwCwmJmUeD1wP81s7HmsuD9L4Avm9m7gC3AIWA40zWKiGSjgg0O4r2tV9x9zZkb3P1l4C1wMmDe6u7HM1ueiEh2KthTVe7eBew3sz8EsLgLguU6Mxv72XwM2BRSmSIiWadggsPM7gUeBc4xs4NmtgG4DthgZk8DOzg1CP4G4HkzewFoAP4+hJJFRLKS6bbqIiKSjILpcYiISGoUxOB4XV2dNzY2hl2GiEhOeeKJJzrdvf7M9oIIjsbGRrZt2xZ2GSIiOcXMXpyoXaeqREQkKQoOERFJioJDRESSouAQEZGkKDhERCQpCg4REUmKgkNERJKi4JjET3a1cfvDe8IuQ0Qkqyg4JrF1zxG+tHk3o6O6n5eIyBgFxySaYlH6h0Y59MqJsEsREckaCo5JNMWiAOxu7w65EhGR7KHgmMRYcOxp7wm5EhGR7KHgmMScylLqomXsblNwiIiMUXBMoSlWxZ4OBYeIyBgFxxSaY9Xsae9BT0oUEYlTcEyhKRalu3+Y9u6BsEsREckKCo4paIBcROR0Co4pNCs4REROo+CYQn11GdXlEV3LISISUHBMwcxojkXV4xARCSg4pqEpFmVPe2/YZYiIZAUFxzQ0xaJ09gzwSt9g2KWIiIROwTENzbFqQAPkIiKQxuAws01m1m5m2xNsv87MngleW83sgqB9iZk9ZGY7zWyHmX1o3DGfMLNDZvZU8LoqXfWPd+pmhwoOEZF09jjuBNZOsn0/cJm7rwZuBTYG7cPAR9z91cAlwPvN7Lxxx93m7muC1w/SUPevWTSngvKSIvU4RERIY3C4+xbg6CTbt7r7sWD1MWBx0N7q7k8Gy93ATmBRuuqcjqIiY0W9ZlaJiED2jHFsAO4/s9HMGoELgZ+Pa745OL21yczmJvpAM7vRzLaZ2baOjo5ZF9ikKbkiIkAWBIeZvZF4cNxyRnsU+C/gw+7eFTR/FVgBrAFagS8k+lx33+juLe7eUl9fP+s6m2NRDr1ygt6B4Vl/lohILgs1OMxsNXAHsM7dj4xrLyEeGve4+31j7e7e5u4j7j4KfA24KFO1jg2Q7+vQ9RwiUthCCw4zWwrcB6x39xfGtRvwdWCnu3/xjGMWjlu9BphwxlY66DGyIiJxkXR9sJndC7wBqDOzg8DfACUA7v4vwMeB+cDt8axg2N1bgEuB9cCzZvZU8HF/Fcyg+qyZrQEcOAC8N131n2nZ/CoiRaZxDhEpeGkLDnd/5xTbbwBumKD9EcASHLM+NdUlr6S4iMa6Kl3LISIFL/TB8VzSVB9lr4JDRAqcgiMJzQ1RXjzax8DwSNiliIiERsGRhKZYlJFR50BnX9iliIiERsGRBD1GVkREwZGUFfVRzBQcIlLYFBxJKC8pZvHcCl3LISIFTcGRpOZYtXocIlLQFBxJaopF2dfZy8ioh12KiEgoFBxJaqqPMjg8yq+OamaViBQmBUeSmho0s0pECpuCI0l6jKyIFDoFR5JqykuIVZepxyEiBUvBMQPNDVH2dCg4RKQwKThmYOxmh+6aWSUihUfBMQNNDdX0DAxzuKs/7FJERDJOwTEDTfWaWSUihUvBMQMnZ1a1KThEpPAoOGagLlrKnMoSDZCLSEFScMyAmdFUH9WpKhEpSAqOGWqKKThEpDApOGaoKRblaO8gR3oGwi5FRCSjFBwzpKcBikihUnDMUHNDNYAGyEWk4Cg4Zuis2nIqS4vV4xCRgqPgmCEzY4VmVolIAVJwzEKzZlaJSAFScMzCiliU1uP9dPcPhV2KiEjGKDhmYWxm1d6O3pArERHJHAXHLDRrSq6IFCAFxywsnVdJaXERu9u7wy5FRCRjFByzECkuorGukr3qcYhIAVFwzFJzrFqnqkSkoCg4ZmlFLMpLR/voHxoJuxQRkYxQcMxScyzKqMP+Ts2sEpHCkLbgMLNNZtZuZtsTbL/OzJ4JXlvN7IKgfYmZPWRmO81sh5l9aNwx88zsQTPbHbzPTVf906WbHYpIoUlnj+NOYO0k2/cDl7n7auBWYGPQPgx8xN1fDVwCvN/Mzgu2fRTY7O7NwOZgPVRn11VRZLBbwSEiBSJtweHuW4Cjk2zf6u7HgtXHgMVBe6u7PxksdwM7gUXBfuuAu4Llu4CrU195cspLilk6TzOrRKRwZMsYxwbg/jMbzawRuBD4edDU4O6tEA8YIJboA83sRjPbZmbbOjo6Ul/xOHoaoIgUktCDw8zeSDw4bjmjPQr8F/Bhd+9K9nPdfaO7t7h7S319fWqKTWBFLMq+zh6GR0bT+nVERLJBqMFhZquBO4B17n5kXHsJ8dC4x93vG3dIm5ktDPZZCLRnst5EmmPVDI04Lx3tC7sUEZG0Cy04zGwpcB+w3t1fGNduwNeBne7+xTMO+x5wfbB8PfDdTNQ6lbGZVRogF5FCkM7puPcCjwLnmNlBM9tgZjeZ2U3BLh8H5gO3m9lTZrYtaL8UWA9cHrQ/ZWZXBds+DVxhZruBK4L10GlKrogUkki6Ptjd3znF9huAGyZofwSwBMccAd6UkgJTKFoWYWFtuWZWiUhBCH1wPF80xaI6VSUiBUHBkSJNsSh7O3oYHfWwSxERSSsFR4o0xaL0DY7Q2tUfdikiImml4EiRpvpgZlWbHuokIvlNwZEizQ3VgGZWiUj+U3CkyLyqUuZVlSo4RCTvKThSSPesEpFCoOBIobEpue6aWSUi+UvBkUJN9VGOnxiis2cw7FJERNJGwZFCzQ269YiI5D8FRwqdvGdVh4JDRPKXgiOFFtSUEy2LsEfXcohIHlNwpJCZsSIWVY9DRPKagiPFmuo1JVdE8puCI8WaYlHaugbo6h8KuxQRkbRQcKRYsx7qJCJ5TsGRYidnVrUpOEQkPyk4UmzJvEpKI0UaIBeRvKXgSLHiImN5XZVOVYlI3lJwpEH8nlW6lkNE8pOCIw2aY9UcPHaC/qGRsEsREUk5BUcaNMWiuMNejXOISB5ScKRBk6bkikgeU3CkQWNdJcVFpuAQkbw0reAwsyozKwqWX2VmbzazkvSWlrvKIsUsm1fJbl3LISJ5aLo9ji1AuZktAjYDfwrcma6i8kGTbnYoInlqusFh7t4HvAX4Z3e/BjgvfWXlvqZYlAOdvQyNjIZdiohISk07OMzsdcB1wH8HbZH0lJQfmmJRhkedF4/0hl2KiEhKTTc4Pgx8DPiOu+8ws+XAQ2mrKg80x6oBzawSkfwzrV6Du/8U+ClAMEje6e4fTGdhuW5FrApQcIhI/pnurKpvmVmNmVUBzwHPm9lfpre03FZZGmHRnAp2KzhEJM9M91TVee7eBVwN/ABYCqxPV1H5oimmpwGKSP6ZbnCUBNdtXA18192HAE9bVXmiKRZlb0cPo6P6UYlI/phucPwrcACoAraY2TKgK11F5YumWJT+oVEOvXIi7FJERFJmWsHh7l9y90XufpXHvQi8cbJjzGyTmbWb2fYE268zs2eC11Yzu2CqY83sE2Z2yMyeCl5XTaf+sOgxsiKSj6Y7OF5rZl80s23B6wvEex+TuRNYO8n2/cBl7r4auBXYOM1jb3P3NcHrB9OpPyxjNzvUszlEJJ9M91TVJqAbeHvw6gK+MdkB7r4FODrJ9q3ufixYfQxYPN1jc8WcylLqomXqcYhIXplucKxw979x933B65PA8hTWsQG4f5r73hyc3tpkZnMT7WRmN471kDo6OlJT5Qw0xfQYWRHJL9MNjhNm9ptjK2Z2KZCSEV8zeyPx4LhlGrt/FVgBrAFagS8k2tHdN7p7i7u31NfXp6LUGYk/RrYHd82sEpH8MN37Td0E3G1mtcH6MeD62X5xM1sN3AFc6e5Hptrf3dvGHfs14PuzrSHdmmPVdPcP09E9QKymPOxyRERmbbqzqp529wuA1cBqd78QuHw2X9jMlgL3Aevd/YVpHrNw3Oo1wIQztrKJngYoIvkmqScAuntXcAU5wP+ebF8zuxd4FDjHzA6a2QYzu8nMbgp2+TgwH7g9mFq7bbJjg02fNbNnzewZ4tOB/zyZ+sNwamaVgkNE8sNsbo1uk21093dOsf0G4IZkjnX3nLvNSay6jOryiHocIpI3ZvPMcY32ToOZBQPkupZDRPLDpD0OM+tm4oAwoCItFeWh5liUn+wKb0qwiEgqTdrjcPdqd6+Z4FXt7noC4DQ1xaJ09gzwSt9g2KWIiMzabE5VyTRpZpWI5BMFRwboMbIikk8UHBmwaE4F5SVFCg4RyQsKjgwoKjKW10V1LYeI5AUFR4Y0N+gxsiKSHxQcGdJUH+XQKyfoGxwOuxQRkVlRcGTI2Myqve29IVciIjI7Co4MaW4IpuR26ApyEcltCo4MWTa/ikiRsbtN4xwiktsUHBlSUlxEY52eBigiuU/BkUFN9VH2dCg4RCS3KTgyqCkW5cUjfQwOj4ZdiojIjCk4Mqi5IcrIqHPgiGZWiUjuUnBk0Ip63exQRHKfgiODVtRHMUMzq0Qkpyk4MqiitJjFcys0QC4iOU3BkWFN9VF2t+kiQBHJXQqODGtuqGZfZy8jo3pku4jkJgVHhjXVRxkcHuXgsb6wSxERmREFR4atCG52qAFyEclVCo4MO/n8cQ2Qi0iOUnBkWG1FCQ01ZTy0q52hEV1BLiK5R8ERgg9c3szP9x/l5m89qduPiEjOUXCE4I8vWcYn/uA8frijTeEhIjlHwRGSd116Np988/n86Lk23q/wEJEcouAI0fWvb+Rv153Pg8+18b57FB4ikhsUHCH7k9c1cuu68/nxzjbed88TDAyPhF2SiMikFBxZYP3rGrn16pX8eGc77/vmkwoPEclqCo4ssf6SZfz9NSvZvKudP1N4iEgWU3BkkesuXsanrlnFT3a1c9O/PUH/kMJDRLKPgiPL/NHFS/nUNat46PkObvqmwkNEsk/agsPMNplZu5ltT7D9OjN7JnhtNbMLpjrWzOaZ2YNmtjt4n5uu+sP0Rxcv5dNvWcXDz3fwXvU8RCTLpLPHcSewdpLt+4HL3H01cCuwcRrHfhTY7O7NwOZgPS+946KlfOatq9iyu4MbFR4ikkXSFhzuvgU4Osn2re5+LFh9DFg8jWPXAXcFy3cBV6ek2Cx17W8s5TNvWc3/7O7gPXdvU3iISFbIljGODcD909ivwd1bAYL3WKIdzexGM9tmZts6OjpSVGbmvf03lvCZt67mkT2dCg8RyQqhB4eZvZF4cNySys91943u3uLuLfX19an86Ix7e8sSPqvwEJEsEWpwmNlq4A5gnbsfmcYhbWa2MDh2IdCezvqyyR+2LOFzb7uAR/Z0csNd2zgxqPAQkXCEFhxmthS4D1jv7i9M87DvAdcHy9cD301Hbdnqba9dzOffdgE/29vJDXc/rvAQkVCkczruvcCjwDlmdtDMNpjZTWZ2U7DLx4H5wO1m9pSZbZvs2GDTp4ErzGw3cEWwXlDe+trFfOEPL2Dr3iNsuEvhISKZZ+4edg1p19LS4tu2bZt6xxzynV8e5CPffpqLz57P19/VQmVpJOySRCTPmNkT7t5yZnvog+MyM9dcuJjbrl3Dz/cf4d13Pk7f4HDYJYlIgVBw5LB1axZx27Vr+MX+o/zpNxQeIpIZCo4cNxYejx84yru+8TjHTwyFXZKI5DkFRx5Yt2YR//SOC3nixWO84XMP8Y2f7dfTBEUkbRQceeIPLjiL777/Us4/q5ZP/r/n+J0v/pTvP/MyhTD5QUQyS8GRR1YuquXfNlzEXe++iMrSYm7+1i+5+vat/GJ/wluGiYgkTcGRZ8yMy15Vz39/8Lf43NtW03a8n7f/66PccNc29rT3hF2eiOQBXceR504MjrDpZ/v56sN7OTE0wrW/sYQP/04zserysEsTkSyX6DoOBUeBONIzwD//ZA/ffOxFSiNF3Pjby3nPby2nqkwXDorIxBQcBR4cYw509vK5Hz7Pfz/bSl20jD+/oplrW5YQKdZZSxE5na4cFwAa66r4ynWv4b73vZ6z6yr56+9s5/f+cQsPPtemGVgiMi0KjgL1mqVz+fZ7X8fG9a/FgffcvY1rNz7GU796JezSRCTLKTgKmJnxu+cv4Ecf/m3+7uqV7Ovo4eqv/Iz3f+tJXjzSG3Z5IpKlNMYhJ/UMDPO1LfvYuGUfw6Oj/PEly/jA5c3MqyoNuzQRCYEGxxUc09be1c9tP97Nfzz+ElWlEd572XLe9tolLKjVFF6RQqLgUHAkbXdbN595YBc/3hl/Qu+FS+dw5coFXLlyIUvmVYZcnYikm4JDwTFje9p7eGB7K/dvP8yOl7sAOP+sGq5atZC1Kxewoj4acoUikg4KDgVHSrx0pI8HdsRD5JcvvQLAqxqirF25kCtXLuDcBdWYWbhFikhKKDgUHCnXevwED2w/zP3bD/P4gaO4w9l1VaxduYArVy5g1aJahYhIDlNwKDjSqqN7gB89d5gHth9m694jjIw6i+ZUsHblAq5atYALl8ylqEghIpJLFBwKjow51jvIgzvbeGD7YR7Z3cngyCgNNWX83vkLWLtyARc1ztMtTkRygIJDwRGKrv4hHtrVzv3PHubhF9rpHxplXlUpv3teA5efG2P14jk01JTplJZIFlJwKDhC1zc4zMPPd3D/9sP8ZGcbvYMjANRFy1i5qIaVZ9WyclEtKxfVsGhOhcJEJGSJgkP31JaMqSyNcNWqhVy1aiH9QyNsP3Sc7YeO8+yhLna8fJz/2d3JyGj8D5m5lSWsXFTL+WfVsioIk6XzKhUmIllAwSGhKC8ppqVxHi2N80629Q+NsLO1i+0vd7H94HG2v3ycrz+yj6GReJhUl0eCXklN0DOp5ez5VRp0F8kwBYdkjfKSYi5cOpcLl8492TYwPMILh3vY/vJxnj10nB2HjnPXoy8yODwKQFVpMeefVcv5wamuVYtrWV5XpcF3kTRScEhWK4sUs2pxPBDeGbQNjYyyuy0eJmOnu+79xUv0D40GxxTxqoZqzl1QzasX1gSvauZU6maNIqmgwXHJC8Mjo+zr7OXZg8fZ2drFrsPd7Gzt4kjv4Ml9FtaW8+qFNacFytl1VRTrVJfIhDQ4LnktUhzvZbyqofpkm7vT0T3AziBEdrV2sbO1my0vdDAcDMKXRYo4Z8EZvZMFNdRWloT1rYhkPQWH5C0zI1ZTTqymnMteVX+yfWB4hD3tPexs7Y6HyeEufryznW9vO3hyn7Nqyzk3OMUV76XUsGx+JSUaOxFRcEjhKYsEA+pn1Z5sG+udPBf0SnYd7mJnaxc/faHj5BThSJGxbH4ly+ujrKiPsry+ihX1Vayoj2r8RAqKgkOE03snbzgndrJ9YHiE3W097Drczd6OHvZ19LC3o5eHn28/OU0YYF5VKcvrqsYFSvx9yTz1UiT/KDhEJlEWKT55zch4wyOjHDx2IgiTXvZ19rC3vZfNu9r4j22nBuTVS5F8pOAQmYFIcRGNdVU01lXxplefvu143xB7O+OBMtZL2Zegl9I4v5KFtRU01JTTUFPGgtryYLmcBTXlVJQWZ/g7E5la2oLDzDYBvw+0u/vKCbZfB9wSrPYAf+buTwfb1gL/BBQDd7j7p4P2TwDvATqC4/7K3X+Qru9BZCZqK0t4zdK5vGbchYxwqpcy1jvZ19nDgc4+drZ28dDz7fQF9+4ar7o8woKaU2EyUbjURUt1waNkVDp7HHcCXwbuTrB9P3CZux8zsyuBjcDFZlYMfAW4AjgIPG5m33P354LjbnP3z6exbpG0GN9Lufzc07e5Oz0Dw7R19dPWNcDh4/20dffTdjxY7+pn795O2rsHTg7Wjymy+I0iT4ZJbRmx6nLqq8uoj5bF36vLqIuWURpRwMjspS043H2LmTVOsn3ruNXHgMXB8kXAHnffB2Bm/w6sA55DJE+ZGdXlJVSXl9AUq0643+io09k7QHuCcDl4rI8nXjzKsb6hCY+fU1lCXfT0QBkfMHXB+7yqUl0YKQllyxjHBuD+YHkR8Ktx2w4CF49bv9nM/gTYBnzE3Y9N9IFmdiNwI8DSpUtTXrBIGIqKjFh1ObHq8l8bsB9vYHiEIz2DdHQPxF89A3QG72NtTx98hY7ugQlPkRUZzI/+eqDUVpRQVVZMZWmEaPA+tl5VGqGyrJhoWYSySJHuZJzHQg8OM3sj8eD4zbGmCXYb65t/Fbg1WL8V+ALw7ok+1903Ej/9RUtLS/7fV0VknLJIMWfNqeCsORVT7ts7MEznuEAZHy5j7bvbuunoGThtcH8yRcbJIKkqjVBVFqGytPjUe9A2FjpzK0uYV1XK/Ggp86riPZ6a8ojCJ0uFGhxmthq4A7jS3Y8EzQeBJeN2Wwy8DODubeOO/Rrw/QyVKpK34v+BR1g2v2rS/dydgeFRegaG6RsYoXdwmL7BYXoHRugdGKZ3cOTk+untw/QNxpc7ugdOtQWfMZogi0qKjbmVpcyrOvWaXxUES7SUecG2eNiUMrdSp9cyJbTgMLOlwH3Aend/Ydymx4FmMzsbOAS8A/ij4JiF7t4a7HcNsD2DJYsUNDOjvKSY8pJiiKbmM92dE0MjHOsb4mjPIEd6BzjaO8jR3kGO9A5yLHg/2jvIjpe7ONIzQFf/cIL6YE5FCXODgJlbWUptRQk1FSXUlJdQUxGhuryEmvLIaW01FSVESyN6rksS0jkd917gDUCdmR0E/gYoAXD3fwE+DswHbg+6o8Pu3uLuw2Z2M/BD4tNxN7n7juBjP2tma4ifqjoAvDdd9YtI+pkZlaURKksjLJrGaTWI31b/WF88TOJhc3rQxJcHePFIH939Q3T1D9MzMHHYnKoDqsvOCJTykgnXaytKmFNZwtzKEuYE4VRodwfQbdVFJO8Nj8RPsXWdGKarf4iuE0PB+/j14YTtUwVPdVmE2soS5laWMicIlLFgifeCxi0H+9SUl2R9L0e3VReRghUpLor/xz3D27yMD57jJ4Y41jfIsb7B+HLv0KnlvkGO9Q3xq6N9HOuLh1Civ82LjKD3Eg+SaFmEipJiKkuLqSiNTyKoKCmmojTeNtZ+ap+gvSRCeWkRlcG2TIzzKDhERKYw0+AZGXW6xgXK8RODEwbN8b4huvuHae8aoG9omBODo5wYHKZvaCRh8CRSFikKgiZCeUkRn7pmFRcvn5/ch0xBwSEikibFRcbcqlLmVs2spzM2k61vcIQTQyPxMBkcia8HbfHlU+39QVv8mGGqy1P/UDIFh4hIljptJlsWKaypACIiMmsKDhERSYqCQ0REkqLgEBGRpCg4REQkKQoOERFJioJDRESSouAQEZGkFMRNDs2sA3hxhofXAZ0pLCfdcqneXKoVcqveXKoVcqveXKoVZlfvMnevP7OxIIJjNsxs20R3h8xWuVRvLtUKuVVvLtUKuVVvLtUK6alXp6pERCQpCg4REUmKgmNqG8MuIEm5VG8u1Qq5VW8u1Qq5VW8u1QppqFdjHCIikhT1OEREJCkKDhERSYqCYxJmttbMnjezPWb20bDrScTMlpjZQ2a208x2mNmHwq5pKmZWbGa/NLPvh13LVMxsjpn9p5ntCn7Grwu7psmY2Z8H/w62m9m9ZlYedk1jzGyTmbWb2fZxbfPM7EEz2x28zw2zxvES1Pu54N/CM2b2HTObE2KJJ01U67htf2FmbmZ1qfhaCo4EzKwY+ApwJXAe8E4zOy/cqhIaBj7i7q8GLgHen8W1jvkQsDPsIqbpn4AH3P1c4AKyuG4zWwR8EGhx95VAMfCOcKs6zZ3A2jPaPgpsdvdmYHOwni3u5NfrfRBY6e6rgReAj2W6qATu5NdrxcyWAFcAL6XqCyk4ErsI2OPu+9x9EPh3YF3INU3I3Vvd/clguZv4f2yLwq0qMTNbDPwv4I6wa5mKmdUAvw18HcDdB939lVCLmloEqDCzCFAJvBxyPSe5+xbg6BnN64C7guW7gKszWdNkJqrX3X/k7sPB6mPA4owXNoEEP1uA24D/A6RsJpSCI7FFwK/GrR8ki/8zHmNmjcCFwM9DLmUy/0j8H/JoyHVMx3KgA/hGcGrtDjOrCruoRNz9EPB54n9dtgLH3f1H4VY1pQZ3b4X4H0FALOR6kvFu4P6wi0jEzN4MHHL3p1P5uQqOxGyCtqyeu2xmUeC/gA+7e1fY9UzEzH4faHf3J8KuZZoiwGuAr7r7hUAv2XUq5TTB+MA64GzgLKDKzP443Kryk5n9NfHTxPeEXctEzKwS+Gvg46n+bAVHYgeBJePWF5NFXf4zmVkJ8dC4x93vC7ueSVwKvNnMDhA//Xe5mX0z3JImdRA46O5jPbj/JB4k2ep3gP3u3uHuQ8B9wOtDrmkqbWa2ECB4bw+5nimZ2fXA7wPXefZeDLeC+B8QTwe/b4uBJ81swWw/WMGR2ONAs5mdbWalxAcYvxdyTRMyMyN+Dn6nu38x7Hom4+4fc/fF7t5I/Gf6E3fP2r+I3f0w8CszOydoehPwXIglTeUl4BIzqwz+XbyJLB7MD3wPuD5Yvh74boi1TMnM1gK3AG92976w60nE3Z9195i7Nwa/bweB1wT/pmdFwZFAMPh1M/BD4r9433b3HeFWldClwHrif70/FbyuCruoPPIB4B4zewZYA3wq3HISC3pG/wk8CTxL/Hc8a26RYWb3Ao8C55jZQTPbAHwauMLMdhOf/fPpMGscL0G9XwaqgQeD37V/CbXIQIJa0/O1sreXJSIi2Ug9DhERSYqCQ0REkqLgEBGRpCg4REQkKQoOERFJioJDJAXMbGTcVOinUnk3ZTNrnOiOpyJhiYRdgEieOOHua8IuQiQT1OMQSSMzO2BmnzGzXwSvpqB9mZltDp7psNnMlgbtDcEzHp4OXmO3Cyk2s68Fz9n4kZlVhPZNScFTcIikRsUZp6quHbety90vIn7F8T8GbV8G7g6e6XAP8KWg/UvAT939AuL3xBq7W0Ez8BV3Px94BXhrWr8bkUnoynGRFDCzHnePTtB+ALjc3fcFN6I87O7zzawTWOjuQ0F7q7vXmVkHsNjdB8Z9RiPwYPCgI8zsFqDE3f8uA9+ayK9Rj0Mk/TzBcqJ9JjIwbnkEjU9KiBQcIul37bj3R4PlrZx6pOt1wCPB8mbgz+Dkc9lrMlWkyHTprxaR1Kgws6fGrT/g7mNTcsvM7OfE/1B7Z9D2QWCTmf0l8ScM/mnQ/iFgY3Bn0xHiIdKa7uJFkqExDpE0CsY4Wty9M+xaRFJFp6pERCQp6nGIiEhS1OMQEZGkKDhERCQpCg4REUmKgkNERJKi4BARkaT8f12jkiZfcBweAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_hist)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
