{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import math\n",
    "from PIL import Image\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformObj = transforms.Compose([\n",
    "    transforms.Resize(120),\n",
    "    transforms.CenterCrop(120),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot = \"./celeba/\"\n",
    "\n",
    "dataset = datasets.ImageFolder(root=dataroot, transform=transformObj)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, latent_size=20):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        self.latent_size = latent_size\n",
    "        \n",
    "        self.l1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=4, stride=2, padding=1)\n",
    "        self.l2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=4, stride=2, padding=1)        \n",
    "        \n",
    "        self.l21 = nn.Linear(6*2*30*30, self.latent_size)\n",
    "        self.l22 = nn.Linear(6*2*30*30, self.latent_size)\n",
    "        \n",
    "        self.f = nn.Linear(self.latent_size, 6*2*30*30)\n",
    "        \n",
    "        self.l3 = nn.ConvTranspose2d(in_channels=12, out_channels=6, kernel_size=4, stride=2, padding=1)\n",
    "        self.l4 = nn.ConvTranspose2d(in_channels=6, out_channels=3, kernel_size=4, stride=2, padding=1)\n",
    "        \n",
    "    def encoder(self, x_in):\n",
    "        h = F.relu(self.l1(x_in))\n",
    "        h = F.relu(self.l2(h))\n",
    "        \n",
    "        h = h.view(h.size(0), -1)\n",
    "        \n",
    "        return self.l21(h), self.l22(h)\n",
    "    \n",
    "    def decoder(self, z):\n",
    "        z = self.f(z)\n",
    "        z = z.view(z.size(0), 6*2, 30, 30)\n",
    "        \n",
    "        z = F.relu(self.l3(z))\n",
    "        z = torch.sigmoid(self.l4(z))\n",
    "        \n",
    "        return z\n",
    "    \n",
    "    def sampling(self, mu, log_var):\n",
    "        std = torch.exp(0.5*log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return torch.add(eps.mul(std), mu)\n",
    "    \n",
    "    def forward(self, x_in):\n",
    "        mu, log_var = self.encoder(x_in)\n",
    "        z = self.sampling(mu, log_var)\n",
    "        return self.decoder(z), mu, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (l1): Conv2d(3, 6, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (l2): Conv2d(6, 12, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (l21): Linear(in_features=10800, out_features=20, bias=True)\n",
       "  (l22): Linear(in_features=10800, out_features=20, bias=True)\n",
       "  (f): Linear(in_features=20, out_features=10800, bias=True)\n",
       "  (l3): ConvTranspose2d(12, 6, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (l4): ConvTranspose2d(6, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae = VAE()\n",
    "    \n",
    "vae.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 60, 60]             294\n",
      "            Conv2d-2           [-1, 12, 30, 30]           1,164\n",
      "            Linear-3                   [-1, 20]         216,020\n",
      "            Linear-4                   [-1, 20]         216,020\n",
      "            Linear-5                [-1, 10800]         226,800\n",
      "   ConvTranspose2d-6            [-1, 6, 60, 60]           1,158\n",
      "   ConvTranspose2d-7          [-1, 3, 120, 120]             291\n",
      "================================================================\n",
      "Total params: 661,747\n",
      "Trainable params: 661,747\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.16\n",
      "Forward/backward pass size (MB): 0.82\n",
      "Params size (MB): 2.52\n",
      "Estimated Total Size (MB): 3.51\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(vae, (3, 120, 120))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(vae.parameters())\n",
    "\n",
    "def loss_function(recon_x, x, mu, log_var):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp()) # KL Divergence from MIT 6.S191\n",
    "    return (BCE + KLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    vae.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(dataloader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        r_batch, mu, log_var = vae(data)\n",
    "\n",
    "        loss = loss_function(r_batch, data, mu, log_var)\n",
    "\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        #if batch_idx%50==0:\n",
    "        #    print(\"Batch finished in Epoch: \", batch_idx)\n",
    "    print('Epoch: {} Train mean loss: {:.8f}'.format(epoch, train_loss / len(dataloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train mean loss: -1019435.44637161\n",
      "Epoch: 2 Train mean loss: -1028609.07177033\n",
      "Epoch: 3 Train mean loss: -1037917.89274322\n",
      "Epoch: 4 Train mean loss: -1045636.24381978\n",
      "Epoch: 5 Train mean loss: -1053661.66905901\n",
      "Epoch: 6 Train mean loss: -1062967.43440989\n",
      "Epoch: 7 Train mean loss: -1067107.52113238\n",
      "Epoch: 8 Train mean loss: -1074994.69338118\n",
      "Epoch: 9 Train mean loss: -1082275.46152313\n",
      "Epoch: 10 Train mean loss: -1094249.95773525\n",
      "Epoch: 11 Train mean loss: -1101453.58572568\n",
      "Epoch: 12 Train mean loss: -1112642.60007974\n",
      "Epoch: 13 Train mean loss: -1121924.90988836\n",
      "Epoch: 14 Train mean loss: -1132490.45135566\n",
      "Epoch: 15 Train mean loss: -1141355.20334928\n",
      "Epoch: 16 Train mean loss: -1151193.50917065\n",
      "Epoch: 17 Train mean loss: -1161476.62639553\n",
      "Epoch: 18 Train mean loss: -1169279.51315789\n",
      "Epoch: 19 Train mean loss: -1177864.07216906\n",
      "Epoch: 20 Train mean loss: -1183102.15629984\n",
      "Epoch: 21 Train mean loss: -1189510.81060606\n",
      "Epoch: 22 Train mean loss: -1193607.01594896\n",
      "Epoch: 23 Train mean loss: -1197935.58811802\n",
      "Epoch: 24 Train mean loss: -1202209.43082137\n",
      "Epoch: 25 Train mean loss: -1205688.89992026\n",
      "Epoch: 26 Train mean loss: -1209131.82695375\n",
      "Epoch: 27 Train mean loss: -1211454.59170654\n",
      "Epoch: 28 Train mean loss: -1214895.09728868\n",
      "Epoch: 29 Train mean loss: -1216924.78110048\n",
      "Epoch: 30 Train mean loss: -1219641.59011164\n",
      "Epoch: 31 Train mean loss: -1222563.96331738\n",
      "Epoch: 32 Train mean loss: -1224467.83612440\n",
      "Epoch: 33 Train mean loss: -1226499.70115630\n",
      "Epoch: 34 Train mean loss: -1228627.10247209\n",
      "Epoch: 35 Train mean loss: -1229799.08811802\n",
      "Epoch: 36 Train mean loss: -1232210.86443381\n",
      "Epoch: 37 Train mean loss: -1233615.24561404\n",
      "Epoch: 38 Train mean loss: -1235257.46750399\n",
      "Epoch: 39 Train mean loss: -1236078.91228070\n",
      "Epoch: 40 Train mean loss: -1238089.82017544\n",
      "Epoch: 41 Train mean loss: -1239159.67384370\n",
      "Epoch: 42 Train mean loss: -1241010.15470494\n",
      "Epoch: 43 Train mean loss: -1242060.09808612\n",
      "Epoch: 44 Train mean loss: -1243224.64872408\n",
      "Epoch: 45 Train mean loss: -1244108.92304625\n",
      "Epoch: 46 Train mean loss: -1244857.40470494\n",
      "Epoch: 47 Train mean loss: -1246870.93261563\n",
      "Epoch: 48 Train mean loss: -1247282.48086124\n",
      "Epoch: 49 Train mean loss: -1248083.29306220\n",
      "Epoch: 50 Train mean loss: -1249198.92025518\n",
      "Epoch: 51 Train mean loss: -1250228.73285486\n",
      "Epoch: 52 Train mean loss: -1251395.30980861\n",
      "Epoch: 53 Train mean loss: -1252299.61244019\n",
      "Epoch: 54 Train mean loss: -1252762.67105263\n",
      "Epoch: 55 Train mean loss: -1254127.00438596\n",
      "Epoch: 56 Train mean loss: -1254658.50877193\n",
      "Epoch: 57 Train mean loss: -1255420.55183413\n",
      "Epoch: 58 Train mean loss: -1256927.58692185\n",
      "Epoch: 59 Train mean loss: -1257565.07914673\n",
      "Epoch: 60 Train mean loss: -1248878.92145136\n",
      "Epoch: 61 Train mean loss: -1244387.63875598\n",
      "Epoch: 62 Train mean loss: -1248612.43062201\n",
      "Epoch: 63 Train mean loss: -1251396.67942584\n",
      "Epoch: 64 Train mean loss: -1253832.70255183\n",
      "Epoch: 65 Train mean loss: -1256296.59409888\n",
      "Epoch: 66 Train mean loss: -1257676.96570973\n",
      "Epoch: 67 Train mean loss: -1259813.16905901\n",
      "Epoch: 68 Train mean loss: -1260687.82456140\n",
      "Epoch: 69 Train mean loss: -1262299.26754386\n",
      "Epoch: 70 Train mean loss: -1262812.74561404\n",
      "Epoch: 71 Train mean loss: -1263673.67543860\n",
      "Epoch: 72 Train mean loss: -1264648.78229665\n",
      "Epoch: 73 Train mean loss: -1265384.56818182\n",
      "Epoch: 74 Train mean loss: -1266083.32336523\n",
      "Epoch: 75 Train mean loss: -1266985.75558214\n",
      "Epoch: 76 Train mean loss: -1268014.96092504\n",
      "Epoch: 77 Train mean loss: -1268437.14194577\n",
      "Epoch: 78 Train mean loss: -1269175.23843700\n",
      "Epoch: 79 Train mean loss: -1269632.48405104\n",
      "Epoch: 80 Train mean loss: -1270337.25219298\n",
      "Epoch: 81 Train mean loss: -1271039.09051037\n",
      "Epoch: 82 Train mean loss: -1271359.88197767\n",
      "Epoch: 83 Train mean loss: -1272170.40271132\n",
      "Epoch: 84 Train mean loss: -1272658.06020734\n",
      "Epoch: 85 Train mean loss: -1272880.97807018\n",
      "Epoch: 86 Train mean loss: -1273679.64114833\n",
      "Epoch: 87 Train mean loss: -1274289.41347687\n",
      "Epoch: 88 Train mean loss: -1274678.54505582\n",
      "Epoch: 89 Train mean loss: -1275227.56180223\n",
      "Epoch: 90 Train mean loss: -1275711.50598086\n",
      "Epoch: 91 Train mean loss: -1276342.41267943\n",
      "Epoch: 92 Train mean loss: -1276511.22527911\n",
      "Epoch: 93 Train mean loss: -1277168.72328549\n",
      "Epoch: 94 Train mean loss: -1277552.62001595\n",
      "Epoch: 95 Train mean loss: -1277887.44657097\n",
      "Epoch: 96 Train mean loss: -1278387.19856459\n",
      "Epoch: 97 Train mean loss: -1278823.65131579\n",
      "Epoch: 98 Train mean loss: -1279262.70055821\n",
      "Epoch: 99 Train mean loss: -1279591.17862839\n",
      "Epoch: 100 Train mean loss: -1280145.11323764\n"
     ]
    }
   ],
   "source": [
    "n_epoches = 100\n",
    "\n",
    "for epoch in range(1, n_epoches+1):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    z = torch.randn(1, 20).to(device)\n",
    "    for i in range(100):\n",
    "        z = torch.add(z, 0.05)\n",
    "        \n",
    "        sample = vae.decoder(z).to(device)\n",
    "        save_image(sample.view(3, 120, 120), './samplesFACES/sample' + str(i) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
